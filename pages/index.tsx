import Head from 'next/head';
import Link from 'next/Link';
import * as faceapi from "face-api.js";
import { useRef, useState } from "react";
import Webcam from "react-webcam";
import styles from '../styles/Home.module.css'
import { drawDetections } from 'face-api.js/build/commonjs/draw';

function Capture() {
  const initScores = {
    angry: 0,
    disgusted: 0,
    fearful: 0,
    happy: 0,
    neutral: 0,
    sad: 0,
    surprised: 0,
  }
  const webcamRef = useRef<Webcam>(null);
  const [scores, updateScores] = useState<object>(initScores);
  let detectionsWithExpressions : any;

  const loadModels = async () => {
    await Promise.all([
      faceapi.nets.tinyFaceDetector.load('/models'), //ssdMobilenetv1
      faceapi.nets.faceExpressionNet.load('/models'),
    ]);
  };
const faceDetectHandler = async () => {
    await loadModels();
    if (webcamRef.current) {
      // const webcam = webcamRef.current.video as HTMLVideoElement;
      // webcam.width = webcam.videoWidth;
      // webcam.height = webcam.videoHeight;
      const video = webcamRef.current.video as HTMLVideoElement;
      detectionsWithExpressions = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceExpressions()
        console.log(detectionsWithExpressions);
        if (detectionsWithExpressions.length === 1){
          updateScores(detectionsWithExpressions[0].expressions);
          console.log(Object.keys(detectionsWithExpressions[0].expressions));
        } 
    }
  };

  return (
    <>
      <Head>
        <title>Create Next App</title>
        <meta name="description" content="Generated by create next app" />
        <link rel="icon" href="/favicon.ico" />
      </Head>
      <Webcam audio={false} ref={webcamRef} className={styles.video} />
      <button onClick={faceDetectHandler}>いずれは1sおきにキャプチャ</button>
      {/* <ul>
        {Object.entries(scores).forEach((element) => <li key={element[0]}>{element[0]}</li>)}
      </ul> */}
    </>
  );
}

export default Capture
